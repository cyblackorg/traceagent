version: '3.8'

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "5001:5000"
    volumes:
      - ./backend:/app
      - /app/__pycache__
      - /app/.pytest_cache
    environment:
      - FLASK_ENV=development
      - FLASK_DEBUG=1
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      # LLM Provider Configuration (uncomment and configure as needed)
      # - LLM_PROVIDER=deepseek
      # - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - LLM_PROVIDER=openai
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=gpt-4
      # - LLM_PROVIDER=anthropic
      # - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      # - LLM_PROVIDER=google
      # - GOOGLE_API_KEY=${GOOGLE_API_KEY}
    networks:
      - traceagent-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    command: ["python3", "-m", "flask", "run", "--host=0.0.0.0", "--port=5000", "--reload", "--debug"]

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true
      - REACT_APP_API_URL=http://localhost:5001
      - FAST_REFRESH=true
      - GENERATE_SOURCEMAP=false
    networks:
      - traceagent-network
    depends_on:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    stdin_open: true
    tty: true

networks:
  traceagent-network:
    driver: bridge

volumes:
  node_modules: 